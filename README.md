# wine_quality_prediction

This project explains the procedure to use AWS services to train ML (Machine Learning) model on multiple parallel EC2(Elastic Compute Cloud) instances. The ML program is written in python using Apache Spark MLlib libraries. The training and prediction programs are configured to run inside a container.

The Python programs used in this project can be found in python_code folder

The Dockerfile for containers can be found in test_docker and train_docker folders

The Datasets used can be found in dataset folder

# Setting up EC2 Cluster on AWS

To run the ML container application for training on multiple parallel EC2 instances, a cluster needs to be set up. The steps given below are followed to create a cluster with 4 instances.

In AWS Management Console search for Elastic Container Service (ECS) and click on it. In ECS Console, select Cluster and click on "Create Cluster"

In Select cluster template click on "EC2 Linux + Networking" , because we will be using Amazon Linux 2 image for managing ECS tasks.

In Configure cluster modify the following parameters and keep the rest as it is.

Cluster name : wine-quality-train-cluster

Provisioning model : On-Demand Instance

EC2 instance type : t2.micro

Number of instances : 4

Key Pair : Choose an appropriate key pair

Security group inbound rules (Port range) : 22-80

Click on "Create" to create a cluster

# Setting up Task Definitions and Tasks

We have successfully created a cluster but there is no task running on our instances. In order to run our ML container application we need to create a "Task Definition" which describes information regarding the containers to use, bind mounts, volumes etc. These are done as follows:

In ECS console select "Task Definitions"
Click on "Create New task Definition"
Choose Select launch type compatibility as "EC2"
This will open up Configure task and container definitions screen where we have to configure the parameters for our docker conatiner to run correctly. The ML conatiner application used for training outputs 2 files, Modelfile and reults.txt. The Modelfile is used in the prediction application and results.txt gives metrics of the training model against ValidationDataset.csv. A bind-mount is required between the Docker container and the host to access these files. Do the following configuration

Task Definition Name : wine-quality-train-task
Task Role : ecsTaskExecutionRole
The following is done so that the files generated by the docker application is available to the host. Under Volumes click on "Add volume"

Name : host-path
Volume type : Bind Mount
Source path : /home/ec2-user
Now we will configure the ML container for training Under Container Definitions click on "Add container"

Container Name : wine-train-container
Memory Limits : *Soft Limit, 512
Under Mount points ,

Source volume : host-path
Container path : /job
Click on "Add" and then click on "Create"

We have successfully created our "Task Definition" , now we have create a Task which will initiate our docker container application on the EC2 instances. Do the following to run the task:

On ECS console click on Cluster
Select the cluster recently created (wine-train-quality-cluster)
Select Tasks tab and click on "Run new Task"
Select Launch type as "EC2" and select Number of Task as "4"
Click on "Run Task"
This will download ML conatiner application for training on EC2 instances if not present and starts executing it. Once the execution is completed two files named "Modelfile" and "results.txt" should be present in the home directory (/home/ec2-user) of all the running EC2 instances. This "Modelfile" can be downloaded from any one these instances which will be used in the prediction application. Instructions to download using WinSCP is given at Using WinSCP to transfer data

# Running the Prediction Application on AWS with Docker

The ML container for prediction uses 2 files as input "Modelfile", "TestDataset.csv" . The container application takes the "TestDataset.csv" as input and applies the model from "Modelfile" and generates a csv file with prediction output. The detailed steps are explained below.

# Launching an instance on AWS
Ubuntu instance is launched as follows :

Go to EC2 dashboard and click on "Launch instances"
In Choose an Amazon Machine Image (AMI) select "Amazon Linux 2 AMI (HVM), SSD Volume Type"
In Choose an Instance type select "t2.micro" and click on "Review and Launch"
CLick on "Launch"
Create a New key pair or choose an existing one and click on "Launch"

# Installing Docker and downloading the prediction container

In order to run the prediction conatiner docker package is required. To install docker in Amazon linux machine the following steps are done

Run the following command
    $ sudo yum install docker -y && sudo systemctl start docker
The docker is pulled with the following command
    $ sudo docker pull tanisharajput/winetest:latest
Run the following command to verify if the container has been installed
    $ sudo docker images

# Running the docker container

After installing the image, two files must be present in order to run the container application properly (Modelfile and Inputdataset.csv). These two files can be uploaded on to the instances using WinSCP. To run the container use the following command

  $ sudo docker run -v /home/ec2-user/:job tanisharajput/winetest:latest TestDataset.csv
where , /home/ec2-user is the path to the home directory in the instance. /job is the path mapped inside the conatiner tanisharajput/winetest:latest is the name of prediction docker conatiner TestDataset.csv is the name of the input file for prediction testing.

# Running the Prediction Application without Docker

To run the prediction application without docker, the following packages are needed 

# Conclusion

Utilized AWS EMR to create a Spark cluster for distributed data processing.
Employed Spark to build a wine quality prediction ML model, leveraging its parallel computing capabilities across multiple EC2 instances for efficient model training.
Trained the ML model on a dataset of wine features and quality ratings.
Implemented model saving and loading functionalities to ensure seamless integration into the prediction application.
Developed an application running on a single EC2 instance to perform wine quality prediction using the trained model.
# Program Output: 
The application provided predictions for wine quality based on input features, allowing users to assess the quality of wine samples.
Pyspark
JAVA JDK
numpy
Apache Spark(spark-3.0.1-bin-hadoop2.7.tgz)
